{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioi_utils import *\n",
    "from circuit_utils import *\n",
    "from sae_variants import *\n",
    "from sae_interp import *\n",
    "from sae_interventions import *\n",
    "from training import *\n",
    "from mandala._next.imports import *\n",
    "from mandala._next.common_imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not find model\n"
     ]
    }
   ],
   "source": [
    "from circuit_utils import *\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "if 'model' in locals():\n",
    "    MODELS[MODEL_ID] = model\n",
    "\n",
    "HEAD_CLASS_FIG = {\n",
    "    'nm': 'Name Mover',\n",
    "    'bnm': 'Backup Name Mover',\n",
    "    'ind': 'Induction',\n",
    "    'nnm': 'Negative Name Mover',\n",
    "    'si': 'S-Inhibition',\n",
    "    'dt': 'Duplicate Token',\n",
    "    'pt': 'Previous Token',\n",
    "}\n",
    "\n",
    "COMPONENT_NAME_FIG = {\n",
    "    'k': 'Key',\n",
    "    'v': 'Value',\n",
    "    'q': 'Query',\n",
    "    'z': 'Attn Output',\n",
    "}\n",
    "\n",
    "CROSS_SECTION_FIG = {\n",
    "    'ind+dt@z': 'Ind+DT out',\n",
    "    'nm+bnm@q': '(B)NM q',\n",
    "    'nm+bnm@qk': '(B)NM qk',\n",
    "    'nm+bnm@z': '(B)NM out',\n",
    "    'si@v': 'S-I v',\n",
    "    'si@z': 'S-I out',\n",
    "}\n",
    "\n",
    "c = Circuit()\n",
    "paper_cross_sections = [\n",
    "    # IO\n",
    "    (c.zs(c.nm + c.bnm), ('io',), 'nm+bnm@z'),\n",
    "    (c.qs(c.nm + c.bnm) + c.ks(c.nm + c.bnm), ('io',), 'nm+bnm@qk'),\n",
    "    (c.qs(c.nm + c.bnm), ('io',), 'nm+bnm@q'),\n",
    "    # S\n",
    "    (c.qs(c.nm + c.bnm) + c.ks(c.nm + c.bnm), ('s',), 'nm+bnm@qk'),\n",
    "    (c.qs(c.nm + c.bnm), ('s',), 'nm+bnm@q'),\n",
    "    (c.vs(c.si), ('s',), 'si@v'),\n",
    "    (c.zs(c.si), ('s',), 'si@z'),\n",
    "    (c.zs(c.ind) + c.zs(c.dt), ('s',), 'ind+dt@z'),\n",
    "    # Pos\n",
    "    (c.qs(c.nm + c.bnm) + c.ks(c.nm + c.bnm), ('io_pos',), 'nm+bnm@qk'),\n",
    "    (c.qs(c.nm + c.bnm), ('io_pos',), 'nm+bnm@q'),\n",
    "    (c.zs(c.si), ('io_pos',), 'si@z'),\n",
    "    (c.vs(c.si), ('io_pos',), 'si@v'),\n",
    "    # Pos + S\n",
    "    (c.qs(c.nm + c.bnm) + c.ks(c.nm + c.bnm), ('io_pos', 's'), 'nm+bnm@qk'),\n",
    "    (c.zs(c.si), ('io_pos', 's'), 'si@z'),\n",
    "    (c.vs(c.si), ('io_pos', 's'), 'si@v'),\n",
    "    (c.zs(c.ind) + c.zs(c.dt), ('io_pos', 's'), 'ind+dt@z'),\n",
    "    (c.zs(c.ind) + c.zs(c.dt), ('io_pos',), 'ind+dt@z'),\n",
    "    # All\n",
    "    (c.qs(c.nm + c.bnm) + c.ks(c.nm + c.bnm), ('io', 'io_pos', 's'), 'nm+bnm@qk'),\n",
    "]\n",
    "\n",
    "locations_displaynames = {\n",
    "    'nm+bnm@z': '(B)NM out',\n",
    "    'nm+bnm@qk': '(B)NM qk',\n",
    "    'nm+bnm@q': '(B)NM q',\n",
    "    'si@v': 'S-I v',\n",
    "    'si@z': 'S-I out',\n",
    "    'ind+dt@z': 'Ind+DT out',\n",
    "}\n",
    "\n",
    "NODES = c.zs(c.nm + c.bnm) + c.qs(c.nm + c.bnm) + c.zs(c.si) + [n for n in c.vs(c.si) if n.seq_pos == 's2'] + c.zs(c.ind) + c.zs(c.dt) + c.ks(c.nm + c.bnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = '/media/amakelov/SanDisk1TB/paper_sprint/test.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Storage(db_path=DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amakelov/workspace/current/conda_envs/serimats/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "MODELS[MODEL_ID] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logging level to debug\n",
    "from mandala._next.common_imports import logger\n",
    "import logging\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# nodes = list(c.nodes.keys())\n",
    "# circuit_nodes = list(c.nodes.keys())\n",
    "\n",
    "with storage:\n",
    "\n",
    "    ############################################################################ \n",
    "    ### prompt dataset for training supervised features\n",
    "    ############################################################################ \n",
    "    P_train = generate_prompts(\n",
    "        distribution=full_distribution,\n",
    "        patterns=['ABB', 'BAB'],\n",
    "        prompts_per_pattern=10_000,\n",
    "        random_seed=0,\n",
    "    )\n",
    "    N_TRAIN = len(storage.unwrap(P_train))\n",
    "    ### activations for training supervised features\n",
    "    As_train = run_with_cache(\n",
    "        prompts=P_train, \n",
    "        nodes=NODES,\n",
    "        batch_size=100,\n",
    "        model_id=MODEL_ID,\n",
    "        verbose=True,\n",
    "    )\n",
    "    A_TRAIN_DICT = {node: A for node, A in zip(NODES, As_train)}\n",
    "\n",
    "    # ### precompute the mean logit difference for clean training data\n",
    "    # logits_train_clean = run_with_hooks(prompts=P_train, hooks=[], batch_size=200,)\n",
    "    # CLEAN_LD_MEAN = (storage.unwrap(logits_train_clean)[:, 0] - storage.unwrap(logits_train_clean)[:, 1]).mean().item()\n",
    "\n",
    "    # ### precompute the mean-ablated logit difference when ablating each node\n",
    "    # A_TRAIN_MEAN_DICT = {node: get_dataset_mean(A) for node, A in A_TRAIN_DICT.items()}\n",
    "\n",
    "    # MEAN_ABLATED_LD_DICT = {}\n",
    "    # for node, A in A_TRAIN_DICT.items():\n",
    "    #     MEAN_ABLATED_LD_DICT[node] = compute_mean_ablated_lds(\n",
    "    #         node=node, prompts=P_train, A_mean=A_TRAIN_MEAN_DICT[node], batch_size=200,\n",
    "    #     )\n",
    "\n",
    "    ############################################################################ \n",
    "    ### prompt dataset for editing and other evaluations\n",
    "    ############################################################################ \n",
    "    N_NAMES = len(NAMES)\n",
    "    editing_base_distribution = copy.deepcopy(full_distribution)\n",
    "    editing_base_distribution.names = editing_base_distribution.names[:N_NAMES // 2]\n",
    "    editing_source_distribution = copy.deepcopy(full_distribution)\n",
    "    editing_source_distribution.names = editing_source_distribution.names[N_NAMES // 2:]\n",
    "\n",
    "    P_eval = generate_prompts(\n",
    "        distribution=editing_base_distribution,\n",
    "        patterns=['ABB', 'BAB'],\n",
    "        prompts_per_pattern=2500,\n",
    "        random_seed=1,\n",
    "    )\n",
    "    As_eval = run_with_cache(\n",
    "        prompts=P_eval, \n",
    "        nodes=NODES,\n",
    "        batch_size=100,\n",
    "        model_id=MODEL_ID,\n",
    "        verbose=True,\n",
    "    )\n",
    "    P_eval_feature_idxs = get_prompt_feature_idxs(\n",
    "        prompts=P_eval,\n",
    "        features=[('io',), ('s',), ('io_pos',),],\n",
    "    )\n",
    "    A_EVAL_DICT = {node: A for node, A in zip(NODES, As_eval)}\n",
    "\n",
    "    N_EVAL = len(storage.unwrap(P_eval))\n",
    "    N_NAMES_EVAL_SOURCE = len(editing_source_distribution.names)\n",
    "\n",
    "    ### precompute the mean logit difference for clean training data\n",
    "    logits_eval_clean = run_with_hooks(prompts=P_eval, hooks=[], batch_size=200,)\n",
    "    CLEAN_LD_EVAL_MEAN = (storage.unwrap(logits_eval_clean)[:, 0] - storage.unwrap(logits_eval_clean)[:, 1]).mean().item()\n",
    "\n",
    "    ### precompute the mean-ablated logit difference when ablating each node\n",
    "    A_EVAL_MEAN_DICT = {node: get_dataset_mean(A) for node, A in A_EVAL_DICT.items()}\n",
    "\n",
    "    MEAN_ABLATED_LD_EVAL_DICT = {}\n",
    "    for node, A in A_EVAL_DICT.items():\n",
    "        MEAN_ABLATED_LD_EVAL_DICT[node] = compute_mean_ablated_lds(\n",
    "            node=node, prompts=P_eval, A_mean=A_EVAL_MEAN_DICT[node], batch_size=200,\n",
    "        )\n",
    "\n",
    "    ############################################################################ \n",
    "    ### Compute counterfactual prompts and activations\n",
    "    ############################################################################ \n",
    "    ATTRIBUTES = [('io_pos',), ('s',), ('io',), ] # ('s', 'io_pos',), ('io', 'io_pos'), ('s', 'io',), ('io_pos', 's', 'io',), ]\n",
    "\n",
    "    CF_PROMPTS_DICT = {}\n",
    "    for attribute in ATTRIBUTES:\n",
    "        CF_PROMPTS_DICT[attribute] = get_cf_prompts(\n",
    "            prompts=P_eval, \n",
    "            features=attribute,\n",
    "            io_targets=generate_name_samples(N_EVAL, editing_source_distribution.names[:N_NAMES_EVAL_SOURCE // 2]),\n",
    "            s_targets=generate_name_samples(N_EVAL, editing_source_distribution.names[N_NAMES_EVAL_SOURCE//2:]),     \n",
    "        )\n",
    "    ### Compute counterfactual activations\n",
    "    A_EVAL_CF_DICT = {}\n",
    "    for attribute, cf_prompts in tqdm(CF_PROMPTS_DICT.items()):\n",
    "        A_EVAL_CF_DICT[attribute] = run_with_cache(\n",
    "            prompts=cf_prompts, \n",
    "            nodes=NODES,\n",
    "            batch_size=100,\n",
    "            model_id=MODEL_ID,\n",
    "            verbose=True,\n",
    "        )\n",
    "    for attribute in A_EVAL_CF_DICT:\n",
    "        A_EVAL_CF_DICT[attribute] = {node: A_EVAL_CF_DICT[attribute][i] for i, node in enumerate(NODES)}\n",
    "    \n",
    "    P_eval_cf_feature_idxs = {}\n",
    "    for attribute, cf_prompts in CF_PROMPTS_DICT.items():\n",
    "        P_eval_cf_feature_idxs[attribute] = get_prompt_feature_idxs(\n",
    "            prompts=cf_prompts,\n",
    "            features=[attribute],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  8.10it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.84it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.28it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.34it/s]\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.47it/s]\n"
     ]
    }
   ],
   "source": [
    "P_TRAIN_GRADIENTS = get_gradients(storage=storage, nodes=NODES, prompts=P_train, computing=False, n_batches=100)\n",
    "P_EVAL_GRADIENTS = get_gradients(storage=storage, nodes=NODES, prompts=P_eval, computing=False, n_batches=25)\n",
    "P_CF_GRADIENTS = {}\n",
    "for attribute in ATTRIBUTES:\n",
    "    P_CF_GRADIENTS[attribute] = get_gradients(storage=storage, nodes=NODES, prompts=CF_PROMPTS_DICT[attribute], computing=False, n_batches=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing supervised features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with storage:\n",
    "    SUPERVISED_FEATURES_DICT = {}\n",
    "    SUPERVISED_RECONSTRUCTIONS_DICT = {}\n",
    "    for node, A in tqdm(A_TRAIN_DICT.items()):\n",
    "        for eventually in ['independent',]: # 'coupled', 'names', ]:\n",
    "            for codes_type in ('mean',):  # 'mse'):\n",
    "                node_parametrization = get_parametrization(node=node, eventually=eventually, use_names= (eventually == 'names'))\n",
    "                node_features = FEATURE_CONFIGURATIONS[node_parametrization]\n",
    "                code_getter = get_mean_codes if codes_type == 'mean' else lambda features, A, prompts: train_mse_codes(features=features, A=A, prompts=prompts, manual_bias=True)\n",
    "                codes, reconstructions = code_getter(\n",
    "                    features=node_features,\n",
    "                    A=A,\n",
    "                    prompts=P_train,\n",
    "                )\n",
    "                SUPERVISED_FEATURES_DICT[(node, node_parametrization, codes_type)] = codes\n",
    "                SUPERVISED_RECONSTRUCTIONS_DICT[(node, node_parametrization, codes_type)] = reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a uniform schedule for all training runs\n",
    "\n",
    "# use exponentially spread-out checkpoints for the very early stages of training\n",
    "# measure right before resampling, as well as in the middle between resamplings\n",
    "# measure before and after the final LR decay\n",
    "# use two resampling stages, as it seems effects diminish after the first one\n",
    "CHECKPOINT_STEPS = [0, 1, 2, 4, 8, 16, 32, 64, 128, 500, 750, 1000, 1250, 1500, 2000]\n",
    "RESAMPLE_EPOCHS = [501, 1001, ]\n",
    "FINAL_DECAY_START = 1500 # decay the LR for the last 25% of training\n",
    "FINAL_DECAY_END = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAES_DICT = {} # (variant, node, l1, start_epoch) -> encoder\n",
    "EDITED_INTERP_DICT = {} # (variant, node, l1, end_epoch, attribute, num_exchange) -> A_edited\n",
    "EDITED_AGNOSTIC_DICT = {} # (variant, node, l1, end_epoch, attribute, num_exchange) -> A_edited\n",
    "\n",
    "# collecting the weight removed\n",
    "WEIGHT_REMOVED_DICT = {} # (variant, node, l1, end_epoch, attribute, num_exchange, edit_type, ) -> weight_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.preload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m             A_edited, best_features, best_scores, edited_clean, edited_cf \u001b[39m=\u001b[39m get_edit_using_sae_opt(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m                 A_clean_normalized\u001b[39m=\u001b[39mA_eval_normalized,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m                 A_cf_normalized\u001b[39m=\u001b[39mA_eval_cf_normalized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m                 normalization_scale\u001b[39m=\u001b[39mscale,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m             )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m             EDITED_AGNOSTIC_DICT[(\u001b[39m'\u001b[39m\u001b[39mvanilla\u001b[39m\u001b[39m'\u001b[39m, node, l1_coeff, end_epoch, attribute, num_exchange)] \u001b[39m=\u001b[39m A_edited\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m             removed_weight_agnostic \u001b[39m=\u001b[39m compute_removed_weight(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m                 encoder\u001b[39m=\u001b[39;49mencoder,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m                 A_normalized\u001b[39m=\u001b[39;49mA_eval_normalized,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m                 best_features\u001b[39m=\u001b[39;49mbest_features,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m                 batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m             WEIGHT_REMOVED_DICT[(\u001b[39m'\u001b[39m\u001b[39mvanilla\u001b[39m\u001b[39m'\u001b[39m, node, l1_coeff, end_epoch, attribute, num_exchange, \u001b[39m'\u001b[39m\u001b[39magnostic\u001b[39m\u001b[39m'\u001b[39m, )] \u001b[39m=\u001b[39m removed_weight_agnostic\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/amakelov/workspace/current/code/projects/sae/collect_results.ipynb#X24sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m [elt \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m metrics_list \u001b[39mfor\u001b[39;00m elt \u001b[39min\u001b[39;00m x]\n",
      "File \u001b[0;32m~/workspace/current/code/projects/mandala_lite/mandala/_next/model.py:148\u001b[0m, in \u001b[0;36mOp.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     storage \u001b[39m=\u001b[39m Context\u001b[39m.\u001b[39mcurrent_context\u001b[39m.\u001b[39mstorage\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mreturn\u001b[39;00m storage\u001b[39m.\u001b[39;49mcall(\u001b[39mself\u001b[39;49m, args, kwargs, __config__\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39msave_calls\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m})\n",
      "File \u001b[0;32m~/workspace/current/code/projects/mandala_lite/mandala/_next/storage.py:603\u001b[0m, in \u001b[0;36mStorage.call\u001b[0;34m(self, __op__, args, kwargs, __config__)\u001b[0m\n\u001b[1;32m    594\u001b[0m raw_inputs, input_annotations \u001b[39m=\u001b[39m parse_args(\n\u001b[1;32m    595\u001b[0m     sig\u001b[39m=\u001b[39minspect\u001b[39m.\u001b[39msignature(__op__\u001b[39m.\u001b[39mf),\n\u001b[1;32m    596\u001b[0m     args\u001b[39m=\u001b[39margs,\n\u001b[1;32m    597\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m    598\u001b[0m     apply_defaults\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    599\u001b[0m )\n\u001b[1;32m    600\u001b[0m input_tps \u001b[39m=\u001b[39m {\n\u001b[1;32m    601\u001b[0m     k: Type\u001b[39m.\u001b[39mfrom_annotation(annotation\u001b[39m=\u001b[39mv) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m input_annotations\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    602\u001b[0m }\n\u001b[0;32m--> 603\u001b[0m res, main_call, calls \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_internal(\n\u001b[1;32m    604\u001b[0m     op\u001b[39m=\u001b[39;49m__op__,\n\u001b[1;32m    605\u001b[0m     inputs\u001b[39m=\u001b[39;49mraw_inputs,\n\u001b[1;32m    606\u001b[0m     input_tps\u001b[39m=\u001b[39;49minput_tps,\n\u001b[1;32m    607\u001b[0m     _original_args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    608\u001b[0m     _original_kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m    609\u001b[0m )\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m __config__\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msave_calls\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_call(main_call)\n",
      "File \u001b[0;32m~/workspace/current/code/projects/mandala_lite/mandala/_next/storage.py:496\u001b[0m, in \u001b[0;36mStorage.call_internal\u001b[0;34m(self, op, inputs, input_tps, _original_args, _original_kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexists_call(hid\u001b[39m=\u001b[39mcall_hid):\n\u001b[1;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m op\u001b[39m.\u001b[39m__structural__: logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCall to \u001b[39m\u001b[39m{\u001b[39;00mop\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m with hid \u001b[39m\u001b[39m{\u001b[39;00mcall_hid\u001b[39m}\u001b[39;00m\u001b[39m already exists.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 496\u001b[0m     main_call \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_call(hid\u001b[39m=\u001b[39;49mcall_hid, lazy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    497\u001b[0m     \u001b[39mreturn\u001b[39;00m main_call\u001b[39m.\u001b[39moutputs, main_call, input_calls\n\u001b[1;32m    499\u001b[0m \u001b[39m### execute the call if it doesn't exist\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/current/code/projects/mandala_lite/mandala/_next/storage.py:246\u001b[0m, in \u001b[0;36mStorage.get_call\u001b[0;34m(self, hid, lazy)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_call\u001b[39m(\u001b[39mself\u001b[39m, hid: \u001b[39mstr\u001b[39m, lazy: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Call:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmget_call([hid], lazy\u001b[39m=\u001b[39;49mlazy)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/current/code/projects/mandala_lite/mandala/_next/storage.py:220\u001b[0m, in \u001b[0;36mStorage.mget_call\u001b[0;34m(self, hids, lazy)\u001b[0m\n\u001b[1;32m    218\u001b[0m cache_part, db_part \u001b[39m=\u001b[39m split_list(hids, mask)\n\u001b[1;32m    219\u001b[0m \u001b[39m# cache_datas = [self.call_cache.get_data(hid) for hid in tqdm(cache_part)]\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m cache_datas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_cache\u001b[39m.\u001b[39;49mmget_data(call_hids\u001b[39m=\u001b[39;49mcache_part)\n\u001b[1;32m    221\u001b[0m db_datas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_storage\u001b[39m.\u001b[39mmget_data(call_hids\u001b[39m=\u001b[39mdb_part)\n\u001b[1;32m    222\u001b[0m sess\u001b[39m.\u001b[39md()\n",
      "File \u001b[0;32m~/workspace/current/code/projects/mandala_lite/mandala/_next/storage_utils.py:268\u001b[0m, in \u001b[0;36mInMemCallStorage.mget_data\u001b[0;34m(self, call_hids)\u001b[0m\n\u001b[1;32m    266\u001b[0m idx \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mIndexSlice\n\u001b[1;32m    267\u001b[0m filtered_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mloc[idx[call_hids, :], :]\n\u001b[0;32m--> 268\u001b[0m grouped \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39;49mgroupby(level\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    269\u001b[0m groups \u001b[39m=\u001b[39m {key: value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m grouped}\n\u001b[1;32m    270\u001b[0m res_dict \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/workspace/current/conda_envs/serimats/lib/python3.10/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8253\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8254\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8255\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8256\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8257\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8258\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8259\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8260\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8261\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8262\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/current/conda_envs/serimats/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    932\u001b[0m         obj,\n\u001b[1;32m    933\u001b[0m         keys,\n\u001b[1;32m    934\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    935\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    936\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    937\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    938\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/workspace/current/conda_envs/serimats/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:996\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    991\u001b[0m         in_axis \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    993\u001b[0m     \u001b[39m# create the Grouping\u001b[39;00m\n\u001b[1;32m    994\u001b[0m     \u001b[39m# allow us to passing the actual Grouping as the gpr\u001b[39;00m\n\u001b[1;32m    995\u001b[0m     ping \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 996\u001b[0m         Grouping(\n\u001b[1;32m    997\u001b[0m             group_axis,\n\u001b[1;32m    998\u001b[0m             gpr,\n\u001b[1;32m    999\u001b[0m             obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1000\u001b[0m             level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   1001\u001b[0m             sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   1002\u001b[0m             observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   1003\u001b[0m             in_axis\u001b[39m=\u001b[39;49min_axis,\n\u001b[1;32m   1004\u001b[0m             dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   1005\u001b[0m         )\n\u001b[1;32m   1006\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouping)\n\u001b[1;32m   1007\u001b[0m         \u001b[39melse\u001b[39;00m gpr\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1010\u001b[0m     groupings\u001b[39m.\u001b[39mappend(ping)\n\u001b[1;32m   1012\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(groupings) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(obj):\n",
      "File \u001b[0;32m~/workspace/current/conda_envs/serimats/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:604\u001b[0m, in \u001b[0;36mGrouping.__init__\u001b[0;34m(self, index, grouper, obj, level, sort, observed, in_axis, dropna, uniques)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[39mif\u001b[39;00m grouping_vector\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    599\u001b[0m         \u001b[39m# if we have a date/time-like grouper, make sure that we have\u001b[39;00m\n\u001b[1;32m    600\u001b[0m         \u001b[39m# Timestamps like\u001b[39;00m\n\u001b[1;32m    601\u001b[0m         \u001b[39m# TODO 2022-10-08 we only have one test that gets here and\u001b[39;00m\n\u001b[1;32m    602\u001b[0m         \u001b[39m#  values are already in nanoseconds in that case.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m         grouping_vector \u001b[39m=\u001b[39m Series(grouping_vector)\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m--> 604\u001b[0m \u001b[39melif\u001b[39;00m is_categorical_dtype(grouping_vector):\n\u001b[1;32m    605\u001b[0m     \u001b[39m# a passed Categorical\u001b[39;00m\n\u001b[1;32m    606\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_orig_cats \u001b[39m=\u001b[39m grouping_vector\u001b[39m.\u001b[39mcategories\n\u001b[1;32m    607\u001b[0m     grouping_vector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_grouper \u001b[39m=\u001b[39m recode_for_groupby(\n\u001b[1;32m    608\u001b[0m         grouping_vector, sort, observed\n\u001b[1;32m    609\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/current/conda_envs/serimats/lib/python3.10/site-packages/pandas/core/dtypes/common.py:460\u001b[0m, in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    457\u001b[0m     \u001b[39mreturn\u001b[39;00m IntervalDtype\u001b[39m.\u001b[39mis_dtype(arr_or_dtype)\n\u001b[0;32m--> 460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_categorical_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    461\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39m    Check whether an array-like or dtype is of the Categorical dtype.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr_or_dtype, ExtensionDtype):\n\u001b[1;32m    490\u001b[0m         \u001b[39m# GH#33400 fastpath for dtype object\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "collect_metrics = False\n",
    "\n",
    "with storage:\n",
    "    metrics_dfs = []\n",
    "    for node in tqdm(NODES):\n",
    "        A_train = A_TRAIN_DICT[node]\n",
    "        A_train_normalized, scale = normalize_activations(A=A_train)\n",
    "\n",
    "        A_eval = A_EVAL_DICT[node]\n",
    "        A_eval_normalized, _ = normalize_activations(A=A_eval, scale=scale)\n",
    "\n",
    "        for l1_coeff in (0.5, 1.0, 2.5, DefaultConfig.L1_COEFF):\n",
    "            for lr in (DefaultConfig.LR, ):\n",
    "                for batch_size in (512, ):\n",
    "                    for dict_mult in (8, ):\n",
    "                        encoder_state_dict = None\n",
    "                        optimizer_state_dict = None\n",
    "                        scheduler_state_dict = None\n",
    "                        metrics_list = []\n",
    "                        d_hidden = dict_mult * 64\n",
    "                        pbar = tqdm(list(zip(CHECKPOINT_STEPS, CHECKPOINT_STEPS[1:])), disable=True)\n",
    "                        for start_epoch, end_epoch in pbar:\n",
    "                            encoder_state_dict, optimizer_state_dict, scheduler_state_dict, metrics = train_vanilla(\n",
    "                                A=A_train_normalized,\n",
    "                                start_epoch=start_epoch,\n",
    "                                d_hidden=d_hidden,\n",
    "                                end_epoch=end_epoch,\n",
    "                                batch_size=batch_size,\n",
    "                                encoder_state_dict=encoder_state_dict,\n",
    "                                optimizer_state_dict=optimizer_state_dict,\n",
    "                                scheduler_state_dict=scheduler_state_dict,\n",
    "                                l1_coeff=l1_coeff,\n",
    "                                lr=lr,\n",
    "                                resample_epochs=RESAMPLE_EPOCHS,\n",
    "                                final_decay_start=FINAL_DECAY_START,\n",
    "                                final_decay_end=FINAL_DECAY_END,\n",
    "                            )\n",
    "                            if collect_metrics: \n",
    "                                metrics = storage.unwrap(metrics)\n",
    "\n",
    "                            ### compute the logitdiff recovered metric\n",
    "                            encoder = get_vanilla(d_activation=64, d_hidden=d_hidden, encoder_state_dict=encoder_state_dict)\n",
    "                            if collect_metrics:\n",
    "                                logitdiff_loss = get_logitdiff_loss(\n",
    "                                    encoder=encoder, batch_size=100, \n",
    "                                    encoder_normalization_scale=scale,\n",
    "                                    prompts=P_eval,\n",
    "                                    clean_ld=CLEAN_LD_EVAL_MEAN,\n",
    "                                    mean_ablated_ld=MEAN_ABLATED_LD_EVAL_DICT[node],\n",
    "                                    node=node,\n",
    "                                )\n",
    "                                for elt in metrics: elt['ld_loss'] = storage.unwrap(logitdiff_loss)\n",
    "                                metrics_list.append(metrics)\n",
    "\n",
    "\n",
    "                            SAES_DICT[('vanilla', node, l1_coeff, end_epoch)] = encoder\n",
    "                            ### compute high F1-score features\n",
    "                            top_f1_features, top_f1_scores = get_high_f1_features(\n",
    "                                encoder=encoder,\n",
    "                                attributes=[('io',), ('s',), ('io_pos',), ],\n",
    "                                A_normalized=A_eval_normalized,\n",
    "                                prompt_feature_idxs=P_eval_feature_idxs,\n",
    "                                topk=d_hidden,\n",
    "                            )\n",
    "\n",
    "                            # autointerp_fast(\n",
    "                            #     A_normalized=A_eval_normalized,\n",
    "                            #     encoder=encoder,\n",
    "                            #     features=[('io',), ('s',), ('io_pos',), ],\n",
    "                            #     features_to_group=[('io',), ('s',), ],\n",
    "                            #     max_group_size=10,\n",
    "                            #     prompt_feature_idxs=P_eval_feature_idxs,\n",
    "                            #     feature_batch_size=None,\n",
    "                            # )\n",
    "\n",
    "                            ### interp edits\n",
    "                            for attribute in [('io',), ('io_pos',), ]:\n",
    "                                for num_exchange in (2, 4, 8):\n",
    "                                    A_eval_cf = A_EVAL_CF_DICT[attribute][node]\n",
    "                                    A_eval_cf_normalized, _ = normalize_activations(A=A_eval_cf, scale=scale)\n",
    "                                    A_edited, features_removed, features_added = get_edit_using_f1_scores(\n",
    "                                        encoder=encoder,\n",
    "                                        A_clean_normalized = A_eval_normalized,\n",
    "                                        A_cf_normalized = A_eval_cf_normalized,\n",
    "                                        clean_prompts=P_eval,\n",
    "                                        cf_prompts=CF_PROMPTS_DICT[attribute],\n",
    "                                        clean_feature_idxs=P_eval_feature_idxs,\n",
    "                                        cf_feature_idxs=P_eval_cf_feature_idxs[attribute],\n",
    "                                        attribute=attribute,\n",
    "                                        high_f1_features_dict=top_f1_features,\n",
    "                                        normalization_scale=scale,\n",
    "                                        num_exchange=num_exchange,\n",
    "                                    )\n",
    "                                    EDITED_INTERP_DICT[('vanilla', node, l1_coeff, end_epoch, attribute, 2*num_exchange)] = A_edited\n",
    "                                    pbar.set_description(f'Done with {node.displayname} {attribute}')\n",
    "                                    removed_weight_interp = compute_removed_weight(\n",
    "                                        encoder=encoder,\n",
    "                                        A_normalized=A_eval_normalized,\n",
    "                                        best_features=features_removed,\n",
    "                                        batch_size=100,)\n",
    "                                    WEIGHT_REMOVED_DICT[('vanilla', node, l1_coeff, end_epoch, attribute, 2*num_exchange, 'interp', )] = removed_weight_interp\n",
    "\n",
    "                            ### interp-agnostic edits\n",
    "                            for attribute in [('io',), ('io_pos',)]:\n",
    "                                for num_exchange in (4, 8, 16):\n",
    "                                    A_eval_cf = A_EVAL_CF_DICT[attribute][node]\n",
    "                                    A_eval_cf_normalized, _ = normalize_activations(A=A_eval_cf, scale=scale)\n",
    "                                    A_edited, best_features, best_scores, edited_clean, edited_cf = get_edit_using_sae_opt(\n",
    "                                        A_clean_normalized=A_eval_normalized,\n",
    "                                        A_cf_normalized=A_eval_cf_normalized,\n",
    "                                        encoder=encoder,\n",
    "                                        num_exchange=num_exchange,\n",
    "                                        batch_size=200,\n",
    "                                        normalization_scale=scale,\n",
    "                                    )\n",
    "                                    EDITED_AGNOSTIC_DICT[('vanilla', node, l1_coeff, end_epoch, attribute, num_exchange)] = A_edited\n",
    "                                    removed_weight_agnostic = compute_removed_weight(\n",
    "                                        encoder=encoder,\n",
    "                                        A_normalized=A_eval_normalized,\n",
    "                                        best_features=best_features,\n",
    "                                        batch_size=100,)\n",
    "                                    WEIGHT_REMOVED_DICT[('vanilla', node, l1_coeff, end_epoch, attribute, num_exchange, 'agnostic', )] = removed_weight_agnostic\n",
    "\n",
    "                        if collect_metrics:\n",
    "                            all_metrics = [elt for x in metrics_list for elt in x]\n",
    "                            metrics_df = pd.DataFrame(all_metrics)\n",
    "                            metrics_df['l1_coeff'] = l1_coeff\n",
    "                            metrics_df['lr'] = lr\n",
    "                            metrics_df['dict_mult'] = dict_mult\n",
    "                            metrics_df['node'] = node.displayname\n",
    "                            metrics_df['batch_size'] = batch_size\n",
    "                            metrics_dfs.append(metrics_df)\n",
    "        storage.commit()\n",
    "        storage.atoms.clear()\n",
    "\n",
    "    if collect_metrics:\n",
    "        metrics_df_vanilla = pd.concat(metrics_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.preload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(metrics_df_vanilla.query('1000 < epoch < 2000 and l1_coeff == 2.5')).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='ld_loss',\n",
    "    color='node:N',\n",
    "    strokeDash='l1_coeff:N',\n",
    ").properties(width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.query('epoch > 0 and l2_loss < 30.0').node.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "with storage:\n",
    "    metrics_dfs = []\n",
    "    for node in tqdm(NODES):\n",
    "        A_train = A_TRAIN_DICT[node]\n",
    "        A_train_normalized, scale = normalize_activations(A=A_train)\n",
    "\n",
    "        A_eval = A_EVAL_DICT[node]\n",
    "        A_eval_normalized, _ = normalize_activations(A=A_eval, scale=scale)\n",
    "\n",
    "        for l1_coeff in (0.5, 1.0, 2.5, DefaultConfig.L1_COEFF):\n",
    "            for lr in (DefaultConfig.LR, ):\n",
    "                for batch_size in (512, ):\n",
    "                    for dict_mult in (8, ):\n",
    "                        encoder_state_dict = None\n",
    "                        optimizer_state_dict = None\n",
    "                        scheduler_state_dict = None\n",
    "                        metrics_list = []\n",
    "                        d_hidden = dict_mult * 64\n",
    "                        pbar = tqdm(list(zip(CHECKPOINT_STEPS, CHECKPOINT_STEPS[1:])), disable=True)\n",
    "                        for start_epoch, end_epoch in pbar:\n",
    "                            encoder_state_dict, optimizer_state_dict, scheduler_state_dict, metrics = train_gated(\n",
    "                                A=A_train_normalized,\n",
    "                                start_epoch=start_epoch,\n",
    "                                d_hidden=d_hidden,\n",
    "                                end_epoch=end_epoch,\n",
    "                                batch_size=batch_size,\n",
    "                                encoder_state_dict=encoder_state_dict,\n",
    "                                optimizer_state_dict=optimizer_state_dict,\n",
    "                                scheduler_state_dict=scheduler_state_dict,\n",
    "                                l1_coeff=l1_coeff,\n",
    "                                lr=lr,\n",
    "                                resample_epochs=RESAMPLE_EPOCHS,\n",
    "                                final_decay_start=FINAL_DECAY_START,\n",
    "                                final_decay_end=FINAL_DECAY_END,\n",
    "                            )\n",
    "                            metrics = storage.unwrap(metrics)\n",
    "\n",
    "                            # ### compute the logitdiff recovered metric\n",
    "                            encoder = get_gated(d_activation=64, d_hidden=d_hidden, encoder_state_dict=encoder_state_dict)\n",
    "                            logitdiff_loss = get_logitdiff_loss(\n",
    "                                encoder=encoder, batch_size=100, \n",
    "                                encoder_normalization_scale=scale,\n",
    "                                prompts=P_eval,\n",
    "                                clean_ld=CLEAN_LD_EVAL_MEAN,\n",
    "                                mean_ablated_ld=MEAN_ABLATED_LD_EVAL_DICT[node],\n",
    "                                node=node,\n",
    "                            )\n",
    "                            for elt in metrics: elt['ld_loss'] = storage.unwrap(logitdiff_loss)\n",
    "                            metrics_list.append(metrics)\n",
    "\n",
    "                            SAES_DICT[('gated', node, l1_coeff, end_epoch)] = encoder\n",
    "\n",
    "                            ### compute high F1-score features\n",
    "                            top_f1_features, top_f1_scores = get_high_f1_features(\n",
    "                                encoder=encoder,\n",
    "                                attributes=[('io',), ('s',), ('io_pos',), ],\n",
    "                                A_normalized=A_eval_normalized,\n",
    "                                prompt_feature_idxs=P_eval_feature_idxs,\n",
    "                                topk=d_hidden,\n",
    "                            )\n",
    "\n",
    "                            # autointerp_fast(\n",
    "                            #     A_normalized=A_eval_normalized,\n",
    "                            #     encoder=encoder,\n",
    "                            #     features=[('io',), ('s',), ('io_pos',), ],\n",
    "                            #     features_to_group=[('io',), ('s',), ],\n",
    "                            #     max_group_size=10,\n",
    "                            #     prompt_feature_idxs=P_eval_feature_idxs,\n",
    "                            #     feature_batch_size=None,\n",
    "                            # )\n",
    "\n",
    "                            for attribute in [('io',), ('io_pos',), ]:\n",
    "                                for num_exchange in (2, 4, 8):\n",
    "                                    A_eval_cf = A_EVAL_CF_DICT[attribute][node]\n",
    "                                    A_eval_cf_normalized, _ = normalize_activations(A=A_eval_cf, scale=scale)\n",
    "                                    A_edited, features_removed, features_added = get_edit_using_f1_scores(\n",
    "                                        encoder=encoder,\n",
    "                                        A_clean_normalized = A_eval_normalized,\n",
    "                                        A_cf_normalized = A_eval_cf_normalized,\n",
    "                                        clean_prompts=P_eval,\n",
    "                                        cf_prompts=CF_PROMPTS_DICT[attribute],\n",
    "                                        clean_feature_idxs=P_eval_feature_idxs,\n",
    "                                        cf_feature_idxs=P_eval_cf_feature_idxs[attribute],\n",
    "                                        attribute=attribute,\n",
    "                                        high_f1_features_dict=top_f1_features,\n",
    "                                        normalization_scale=scale,\n",
    "                                        num_exchange=num_exchange,\n",
    "                                    )\n",
    "                                    EDITED_INTERP_DICT[('gated', node, l1_coeff, end_epoch, attribute, 2*num_exchange)] = A_edited\n",
    "                                    removed_weight_interp = compute_removed_weight(\n",
    "                                        encoder=encoder,\n",
    "                                        A_normalized=A_eval_normalized,\n",
    "                                        best_features=features_removed,\n",
    "                                        batch_size=100,)\n",
    "                                    WEIGHT_REMOVED_DICT[('gated', node, l1_coeff, end_epoch, attribute, 2*num_exchange, 'interp', )] = removed_weight_interp\n",
    "\n",
    "                            ### interp-agnostic edits\n",
    "                            for attribute in [('io',), ('io_pos',)]:\n",
    "                                for num_exchange in (4, 8, 16):\n",
    "                                    A_eval_cf = A_EVAL_CF_DICT[attribute][node]\n",
    "                                    A_eval_cf_normalized, _ = normalize_activations(A=A_eval_cf, scale=scale)\n",
    "                                    A_edited, best_features, best_scores, edited_clean, edited_cf = get_edit_using_sae_opt(\n",
    "                                        A_clean_normalized=A_eval_normalized,\n",
    "                                        A_cf_normalized=A_eval_cf_normalized,\n",
    "                                        encoder=encoder,\n",
    "                                        num_exchange=num_exchange,\n",
    "                                        batch_size=200,\n",
    "                                        normalization_scale=scale,\n",
    "                                    )\n",
    "                                    EDITED_AGNOSTIC_DICT[('gated', node, l1_coeff, end_epoch, attribute, num_exchange)] = A_edited\n",
    "                                    removed_weight_agnostic = compute_removed_weight(\n",
    "                                        encoder=encoder,\n",
    "                                        A_normalized=A_eval_normalized,\n",
    "                                        best_features=best_features,\n",
    "                                        batch_size=100,)\n",
    "                                    WEIGHT_REMOVED_DICT[('gated', node, l1_coeff, end_epoch, attribute, num_exchange, 'agnostic', )] = removed_weight_agnostic\n",
    "\n",
    "                        all_metrics = [elt for x in metrics_list for elt in x]\n",
    "                        metrics_df = pd.DataFrame(all_metrics)\n",
    "                        metrics_df['l1_coeff'] = l1_coeff\n",
    "                        metrics_df['lr'] = lr\n",
    "                        metrics_df['dict_mult'] = dict_mult\n",
    "                        metrics_df['node'] = node.displayname\n",
    "                        metrics_df['batch_size'] = batch_size\n",
    "                        metrics_dfs.append(metrics_df)\n",
    "        storage.commit()\n",
    "\n",
    "    metrics_df_gated = pd.concat(metrics_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Storage(db_path=DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution SAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "with storage:\n",
    "    metrics_dfs = []\n",
    "    for node in tqdm(NODES):\n",
    "        A_train = A_TRAIN_DICT[node]\n",
    "        A_grad = P_TRAIN_GRADIENTS[node]\n",
    "        A_train_normalized, scale = normalize_activations(A=A_train)\n",
    "        A_grad_normalized = normalize_grad(A_grad=A_grad, scale=scale)\n",
    "\n",
    "        A_eval = A_EVAL_DICT[node]\n",
    "        A_eval_normalized, _ = normalize_activations(A=A_eval, scale=scale)\n",
    "\n",
    "        for l1_coeff in (DefaultConfig.L1_COEFF, 0.5, 1.0, 2.5 ):\n",
    "            for lr in (DefaultConfig.LR, ):\n",
    "                for batch_size in (512, ):\n",
    "                    for dict_mult in (8, ):\n",
    "                        encoder_state_dict = None\n",
    "                        optimizer_state_dict = None\n",
    "                        scheduler_state_dict = None\n",
    "                        metrics_list = []\n",
    "                        d_hidden = dict_mult * 64\n",
    "                        pbar = tqdm(list(zip(CHECKPOINT_STEPS, CHECKPOINT_STEPS[1:])), disable=False)\n",
    "                        for start_epoch, end_epoch in pbar:\n",
    "                            encoder_state_dict, optimizer_state_dict, scheduler_state_dict, metrics = train_attribution(\n",
    "                                A=A_train_normalized,\n",
    "                                A_grad=A_grad_normalized,\n",
    "                                start_epoch=start_epoch,\n",
    "                                d_hidden=d_hidden,\n",
    "                                end_epoch=end_epoch,\n",
    "                                batch_size=batch_size,\n",
    "                                encoder_state_dict=encoder_state_dict,\n",
    "                                optimizer_state_dict=optimizer_state_dict,\n",
    "                                scheduler_state_dict=scheduler_state_dict,\n",
    "                                l1_coeff=l1_coeff,\n",
    "                                # we scale these losses based on the ratio to the other losses, so that they are on the same scale at the start of training\n",
    "                                attribution_sparsity_penalty=1000.0,\n",
    "                                unexplained_attribution_penalty=1000.0,\n",
    "                                lr=lr,\n",
    "                                resample_epochs=RESAMPLE_EPOCHS,\n",
    "                                final_decay_start=FINAL_DECAY_START,\n",
    "                                final_decay_end=FINAL_DECAY_END,\n",
    "                            )\n",
    "                            metrics = storage.unwrap(metrics)\n",
    "\n",
    "                            ### compute the logitdiff recovered metric\n",
    "                            encoder = get_attribution(d_activation=64, d_hidden=d_hidden, encoder_state_dict=encoder_state_dict)\n",
    "                            logitdiff_loss = get_logitdiff_loss(\n",
    "                                encoder=encoder, batch_size=100, \n",
    "                                encoder_normalization_scale=scale,\n",
    "                                prompts=P_eval,\n",
    "                                clean_ld=CLEAN_LD_EVAL_MEAN,\n",
    "                                mean_ablated_ld=MEAN_ABLATED_LD_EVAL_DICT[node],\n",
    "                                node=node,\n",
    "                            )\n",
    "                            for elt in metrics: elt['ld_loss'] = storage.unwrap(logitdiff_loss)\n",
    "                            metrics_list.append(metrics)\n",
    "\n",
    "                            SAES_DICT[('attribution', node, l1_coeff, end_epoch)] = encoder\n",
    "\n",
    "                            metrics = storage.unwrap(metrics)\n",
    "                            # # for elt in metrics: elt['ld_loss'] = storage.unwrap(logitdiff_loss)\n",
    "                            metrics_list.append(metrics)\n",
    "\n",
    "                            # ### compute high F1-score features\n",
    "                            top_f1_features, top_f1_scores = get_high_f1_features(\n",
    "                                encoder=encoder,\n",
    "                                attributes=[('io',), ('s',), ('io_pos',), ],\n",
    "                                A_normalized=A_eval_normalized,\n",
    "                                prompt_feature_idxs=P_eval_feature_idxs,\n",
    "                                topk=d_hidden,\n",
    "                            )\n",
    "\n",
    "                            for attribute in [('io',), ('io_pos',), ]:\n",
    "                                for num_exchange in (2, 4, 8):\n",
    "                                    A_eval_cf = A_EVAL_CF_DICT[attribute][node]\n",
    "                                    A_eval_cf_normalized, _ = normalize_activations(A=A_eval_cf, scale=scale)\n",
    "                                    A_edited, features_removed, features_added = get_edit_using_f1_scores(\n",
    "                                        encoder=encoder,\n",
    "                                        A_clean_normalized = A_eval_normalized,\n",
    "                                        A_cf_normalized = A_eval_cf_normalized,\n",
    "                                        clean_prompts=P_eval,\n",
    "                                        cf_prompts=CF_PROMPTS_DICT[attribute],\n",
    "                                        clean_feature_idxs=P_eval_feature_idxs,\n",
    "                                        cf_feature_idxs=P_eval_cf_feature_idxs[attribute],\n",
    "                                        attribute=attribute,\n",
    "                                        high_f1_features_dict=top_f1_features,\n",
    "                                        normalization_scale=scale,\n",
    "                                        num_exchange=num_exchange,\n",
    "                                    )\n",
    "                                    EDITED_INTERP_DICT[('attribution', node, l1_coeff, end_epoch, attribute, 2*num_exchange)] = A_edited\n",
    "                                    removed_weight_interp = compute_removed_weight(\n",
    "                                        encoder=encoder,\n",
    "                                        A_normalized=A_eval_normalized,\n",
    "                                        best_features=features_removed,\n",
    "                                        batch_size=100,)\n",
    "                                    WEIGHT_REMOVED_DICT[('attribution', node, l1_coeff, end_epoch, attribute, 2*num_exchange, 'interp', )] = removed_weight_interp\n",
    "\n",
    "                            for attribute in [('io',), ('io_pos',)]:\n",
    "                                for num_exchange in (4, 8, 16):\n",
    "                                    A_eval_cf = A_EVAL_CF_DICT[attribute][node]\n",
    "                                    A_eval_cf_normalized, _ = normalize_activations(A=A_eval_cf, scale=scale)\n",
    "                                    A_edited, best_features, best_scores, edited_clean, edited_cf = get_edit_using_sae_opt(\n",
    "                                        A_clean_normalized=A_eval_normalized,\n",
    "                                        A_cf_normalized=A_eval_cf_normalized,\n",
    "                                        encoder=encoder,\n",
    "                                        num_exchange=num_exchange,\n",
    "                                        batch_size=200,\n",
    "                                        normalization_scale=scale,\n",
    "                                    )\n",
    "                                    EDITED_AGNOSTIC_DICT[('attribution', node, l1_coeff, end_epoch, attribute, num_exchange)] = A_edited\n",
    "                                    removed_weight_agnostic = compute_removed_weight(\n",
    "                                        encoder=encoder,\n",
    "                                        A_normalized=A_eval_normalized,\n",
    "                                        best_features=best_features,\n",
    "                                        batch_size=100,)\n",
    "                                    WEIGHT_REMOVED_DICT[('attribution', node, l1_coeff, end_epoch, attribute, num_exchange, 'agnostic', )] = removed_weight_agnostic\n",
    "                        \n",
    "\n",
    "                        all_metrics = [elt for x in metrics_list for elt in x]\n",
    "                        metrics_df = pd.DataFrame(all_metrics)\n",
    "                        metrics_df['l1_coeff'] = l1_coeff\n",
    "                        metrics_df['lr'] = lr\n",
    "                        metrics_df['dict_mult'] = dict_mult\n",
    "                        metrics_df['node'] = node.displayname\n",
    "                        metrics_df['batch_size'] = batch_size\n",
    "                        # metrics_df['total_loss'] = (metrics_df['l0_loss'] + metrics_df['l1_loss'] * l1_coeff + metrics_df['attribution_sparsity_loss'] * 1000.0 +\n",
    "                        #                             metrics_df['unexplained_attribution_loss'] * 1000.0)\n",
    "                        metrics_dfs.append(metrics_df)\n",
    "\n",
    "        storage.commit()\n",
    "        # storage.atoms.clear()\n",
    "\n",
    "    metrics_df_attribution = pd.concat(metrics_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save things \n",
    "joblib.dump(value=metrics_df_vanilla, filename='metrics_df_vanilla.joblib')\n",
    "joblib.dump(value=metrics_df_gated, filename='metrics_df_gated.joblib')\n",
    "joblib.dump(value=metrics_df_attribution, filename='metrics_df_attribution.joblib')\n",
    "# now dump the three dicts\n",
    "joblib.dump(value=SAES_DICT, filename='SAES_DICT.joblib')\n",
    "joblib.dump(value=EDITED_INTERP_DICT, filename='EDITED_INTERP_DICT.joblib')\n",
    "joblib.dump(value=EDITED_AGNOSTIC_DICT, filename='EDITED_AGNOSTIC_DICT.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=WEIGHT_REMOVED_DICT, filename='WEIGHT_REMOVED_DICT.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.atoms.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = metrics_df_attribution.node.unique()[0]\n",
    "x = metrics_df_vanilla.query(f'l1_coeff == 5.0')\n",
    "x = x[x.node == node]\n",
    "x['type'] = 'vanilla'\n",
    "y = metrics_df_attribution.copy()\n",
    "y['type'] = 'attribution'\n",
    "combined_df = pd.concat([x, y], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7 * 3 * 2 * 3 * 2  * 20 / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
